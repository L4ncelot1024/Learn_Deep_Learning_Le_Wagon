{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-MNIST-Classification_CHALLENGE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/L4ncelot1024/Learn_Deep_Learning_Le_Wagon/blob/main/01_MNIST_Classification_CHALLENGE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ILz9lkdIwx0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6df6f39-5857-4030-a1ab-b8daaf4ff538"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5WtP4dYIDmc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e39a350-128b-4be5-8ffd-4d562bb98c07"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(f'Tensorflow version {tf.__version__}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmR3pwc8IQXw"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqR0xaMSJsBd"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkuDcpvGI_9-"
      },
      "source": [
        "# Downloading the data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wch2SALSLDyj"
      },
      "source": [
        "#### Data Types and Format\n",
        "\n",
        "First step of a Machine Learning project is to dive into the data and get a sense of the task you're trying to solve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjjCwTjtJOXB"
      },
      "source": [
        "# TODO: check out the shape, the type and the range of the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6Ke7sXU4nov"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(x_train.dtype)\n",
        "print(np.min(x_train), np.max(x_train))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwRtON7LQ02e"
      },
      "source": [
        "# TODO: check output format and the number of classes (set the variables num_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc1PxusD5JTf"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "print(y_train.shape)\n",
        "classes_values = np.unique(y_train)\n",
        "num_outputs = len(classes_values)\n",
        "print(num_outputs)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuEHxKharzRE"
      },
      "source": [
        "#### Displaying the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OYTVYqXJ0hs"
      },
      "source": [
        "# TODO: Display a given image along with its class\n",
        "# hint: make use of the matplotlib.pyplot library already imported as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVbcMf4M5R4S"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "ind = 0\n",
        "plt.imshow(x_train[ind], cmap='Greys')\n",
        "plt.title('')\n",
        "plt.show()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfmh2xF5J9Zn"
      },
      "source": [
        "# TODO: display an image of each class in a grid\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVWXLymy5YFK"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>Hints\n",
        "</summary>\n",
        "\n",
        "In the pyplot library, you can create a figure which will contain a grid of small containers for plot. This is done with the following code\n",
        "`fig, axs = plt.subplots(nrows=2, ncols=5, figsize=(14, 10))`\n",
        "You can read more about it [here](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html) and see an example [here](see an example here: https://matplotlib.org/gallery/images_contours_and_fields/interpolation_methods.html#sphx-glr-gallery-images-contours-and-fields-interpolation-methods-py)\n",
        "\n",
        "Then you just need to loop over the grid of axes (which is 2D if you ask for both several rows and columns)\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "fig, axs = plt.subplots(nrows=2, ncols=5, figsize=(14, 6),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for ax, i in zip(axs.flat, range(num_outputs)):\n",
        "    # Find an image of class i\n",
        "    img_index = np.arange(len(y_train))[y_train == i][0]\n",
        "    ax.imshow(x_train[img_index], cmap='Greys')\n",
        "    ax.set_title(f'Class {i}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCXz4GOEsdxu"
      },
      "source": [
        "# TODO: check the class distribution in the train and test set\n",
        "# a bar plot of the histogram of the number of samples for each class is\n",
        "# a nice way of representing it "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3xB2liS5tmC"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "fraction_per_class_in_train = np.zeros(num_outputs)\n",
        "for i in range(num_outputs):\n",
        "  fraction_per_class_in_train[i] = (y_train == i).sum()\n",
        "fraction_per_class_in_train /= len(y_train)\n",
        "print('Sample distribution in train')\n",
        "print(fraction_per_class_in_train)\n",
        "\n",
        "fraction_per_class_in_test = np.zeros(num_outputs)\n",
        "for i in range(num_outputs):\n",
        "  fraction_per_class_in_test[i] = (y_test == i).sum()\n",
        "fraction_per_class_in_test /= len(y_test)\n",
        "print('Sample distribution in test')\n",
        "print(fraction_per_class_in_test)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4ueduRiLvW1"
      },
      "source": [
        "#### Preparing the data\n",
        "\n",
        "We need to prepare the data for our modeling part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAPCl5GRLzBS"
      },
      "source": [
        "# TODO: Make the input continuous in the range [0, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8j5BBq350Eu"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "x_train_continuous = x_train / 255\n",
        "x_test_continuous = x_test / 255\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAPbiMIPMEZd"
      },
      "source": [
        "# TODO: display again an image to make sure you converted it correctly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekrOGR8z54Vd"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "ind = 0\n",
        "plt.imshow(x_train_continuous[ind], cmap='Greys')\n",
        "plt.show()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwbWnCH3O_xd"
      },
      "source": [
        "# TODO: flatten the input so you can use it in a model, check the size at the end"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v9yMYeA58n-"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "x_train_flatten = x_train_continuous.reshape((len(x_train), -1))\n",
        "x_test_flatten = x_test_continuous.reshape((len(x_test), -1))\n",
        "print(x_train_flatten.shape)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2-LxaV1Mv_p"
      },
      "source": [
        "# TODO: Reduce the size of your training data with a random sample of 10 000 images\n",
        "# (check the numpy function np.random.randint)\n",
        "\n",
        "# here we fix the seed of the random sampling so we all work with the same randomness\n",
        "random_state = 42\n",
        "np.random.seed(random_state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ya_Vshx6BqT"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "idx_sample = np.random.randint(len(x_train_flatten), size=10000)\n",
        "x_train_small = x_train_flatten[idx_sample]\n",
        "y_train_small = y_train[idx_sample]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7oVwDvANKjy"
      },
      "source": [
        "# TODO: check class distribution in sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EId9v18L6Ha0"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "fraction_per_class_in_train = np.zeros(num_outputs)\n",
        "for i in range(num_outputs):\n",
        "  fraction_per_class_in_train[i] = (y_train_small == i).sum()\n",
        "fraction_per_class_in_train /= len(y_train_small)\n",
        "print(fraction_per_class_in_train)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxNt-yB7Mmev"
      },
      "source": [
        "## Linear Model\n",
        "\n",
        "As a review of ML and to build a baseline we start with a simple multinomial logistic regression.\n",
        "\n",
        "TODO: \n",
        "\n",
        "Model fitting: import the model from sklearn and fit it to your sample of data of the train set, print the accuracy on your training sample and on the test data.\n",
        "\n",
        "Model Investigation: Check the confusion matrix and show a mis-labelled image per class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ywXzDPVtwHy"
      },
      "source": [
        "#### Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CAa6BQPMHQz"
      },
      "source": [
        "# TODO: build and fit a LogisticRegression from the package sklearn\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E97_MzSwFD-x"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "lr = LogisticRegression(random_state=random_state, solver='lbfgs', multi_class='multinomial')\n",
        "lr.fit(x_train_small, y_train_small)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WL0bEzXO6cM"
      },
      "source": [
        "# TODO: print train and test metrics of your model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An3isN3YFKhi"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "accuracy_train = lr.score(x_train_small, y_train_small)\n",
        "print(f'Train model accuracy: {accuracy_train}')\n",
        "\n",
        "accuracy_test = lr.score(x_test_flatten, y_test)\n",
        "print(f'Test model accuracy: {accuracy_test}')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-LDmK4qt1NU"
      },
      "source": [
        "#### Inspecting Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4m8xXx0t6Jh"
      },
      "source": [
        "# TODO: Use the provided function to plot the confusion matrix,\n",
        "# try with and without normalization.\n",
        "# Comment your results\n",
        "# you can check example here \n",
        "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 12))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "# To set the number of decimal for numeric types\n",
        "np.set_printoptions(precision=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "019geVmCFuC-"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "y_pred = lr.predict(x_test_flatten)\n",
        "\n",
        "class_names = np.arange(num_outputs)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM9VGAP6QOlE"
      },
      "source": [
        "## TODO: plot mis-labelled sample in test (use plt.subplots )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orw5E9yRF9jd"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "fig, axs = plt.subplots(nrows=2, ncols=5, figsize=(14, 10),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for ax, i in zip(axs.flat, range(num_outputs)):\n",
        "    # Find a miss-classified image of class i\n",
        "    img_index = np.arange(len(y_test))[(y_test == i) & (y_pred != i)][0]\n",
        "    ax.imshow(x_test_continuous[img_index].reshape((28, 28)), cmap='Greys')\n",
        "    ax.set_title(f'Class {i} - Prediction {y_pred[img_index]}')\n",
        "\n",
        "plt.suptitle('Miss-classified samples with LR')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtKmSa7AP6Ke"
      },
      "source": [
        "##Neural Network\n",
        "\n",
        "Now let's try to improve our performance with a simple Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzzJ20jHGazC"
      },
      "source": [
        "### Keras Functional API Overview\n",
        "\n",
        "You have different ways ways for building a model with Tensorflow. Here we choose to use the abstraction provided by Keras, which is now part of Tensorflow so you only have to specify the layers you want and them you wrap them all into a model.\n",
        "\n",
        "You have two main ways of doint this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HTZRBAZGgdq"
      },
      "source": [
        "### Here we'll see two ways of building the exact same model\n",
        "\n",
        "# 1st way: using the Sequential method\n",
        "\n",
        "model1 = tf.keras.Sequential([\n",
        "    # Set input_shape (as a tuple of integers, does not include the samples axis)\n",
        "    # only for the first layer in a model.\n",
        "    tf.keras.layers.Dense(16, activation='relu', input_shape=(64,)),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# 2nd way: Defining layer by layer\n",
        "\n",
        "# This is a placeholder for your input data\n",
        "img_input = tf.keras.layers.Input(shape=(64,))\n",
        "x = tf.keras.layers.Dense(16, activation='relu')(img_input)\n",
        "output = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "model2 = tf.keras.Model(img_input, output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJoaLkuBGgiI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a83b07fb-f4a8-40de-88c6-bc2fa6f4d973"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 2)                 34        \n",
            "=================================================================\n",
            "Total params: 1,074\n",
            "Trainable params: 1,074\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVB3ArUrGggg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "692b8bfe-5f92-474f-ec4d-84b03f2b3806"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 64)]              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 2)                 34        \n",
            "=================================================================\n",
            "Total params: 1,074\n",
            "Trainable params: 1,074\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FXpxD1wY45A"
      },
      "source": [
        "#### Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weh5SOvHQEJf"
      },
      "source": [
        "# TODO: define a keras model using the functional API, try first a simple neural network with only one level of hidden layers\n",
        "# hint: \n",
        "#   - Don't forget to compile your model, you can choose the 'adam' optimizer, chose the correct loss and ask to report the accuracy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D98ZTG4mK0PM"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>Hints\n",
        "</summary>\n",
        "\n",
        "Don't forget to compile your model, you can choose the 'adam' optimizer, then choose the correct loss and ask to report the accuracy\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_outputs, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IajpJrK5RLU3"
      },
      "source": [
        "# TODO: Training your model for 10 epochs and ask to score your test data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXjuWm4lLaDq"
      },
      "source": [
        "\n",
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "history = model.fit(x_train_small,\n",
        "          y_train_small,\n",
        "          epochs=num_epochs,\n",
        "          validation_data=(x_test_flatten, y_test),)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2-B8-VTR8eI"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQUF1n23zX87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "aa53a9fb-b570-42ba-b69b-f23ac9b87b06"
      },
      "source": [
        "# Retrieve the metrics from your history and wrap them into a dataframe\n",
        "# to manipulate them easily\n",
        "history_df = pd.DataFrame(history.history).reset_index().rename(columns={'index': 'epochs'})\n",
        "history_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.530032</td>\n",
              "      <td>0.8532</td>\n",
              "      <td>0.308162</td>\n",
              "      <td>0.9108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.241983</td>\n",
              "      <td>0.9324</td>\n",
              "      <td>0.254201</td>\n",
              "      <td>0.9251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.174773</td>\n",
              "      <td>0.9510</td>\n",
              "      <td>0.220213</td>\n",
              "      <td>0.9346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.134823</td>\n",
              "      <td>0.9625</td>\n",
              "      <td>0.195481</td>\n",
              "      <td>0.9416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.103535</td>\n",
              "      <td>0.9722</td>\n",
              "      <td>0.181387</td>\n",
              "      <td>0.9442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.080170</td>\n",
              "      <td>0.9771</td>\n",
              "      <td>0.182701</td>\n",
              "      <td>0.9443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.062943</td>\n",
              "      <td>0.9829</td>\n",
              "      <td>0.185554</td>\n",
              "      <td>0.9435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0.052074</td>\n",
              "      <td>0.9859</td>\n",
              "      <td>0.171868</td>\n",
              "      <td>0.9486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.038884</td>\n",
              "      <td>0.9908</td>\n",
              "      <td>0.162109</td>\n",
              "      <td>0.9509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0.029759</td>\n",
              "      <td>0.9940</td>\n",
              "      <td>0.158490</td>\n",
              "      <td>0.9542</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epochs      loss  accuracy  val_loss  val_accuracy\n",
              "0       0  0.530032    0.8532  0.308162        0.9108\n",
              "1       1  0.241983    0.9324  0.254201        0.9251\n",
              "2       2  0.174773    0.9510  0.220213        0.9346\n",
              "3       3  0.134823    0.9625  0.195481        0.9416\n",
              "4       4  0.103535    0.9722  0.181387        0.9442\n",
              "5       5  0.080170    0.9771  0.182701        0.9443\n",
              "6       6  0.062943    0.9829  0.185554        0.9435\n",
              "7       7  0.052074    0.9859  0.171868        0.9486\n",
              "8       8  0.038884    0.9908  0.162109        0.9509\n",
              "9       9  0.029759    0.9940  0.158490        0.9542"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goP-Rm780aNV"
      },
      "source": [
        "# TODO: plot on the same plot the val/train curve for each metric\n",
        "# using different colors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ7WScqvLyER"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>Hints\n",
        "</summary>\n",
        "\n",
        "You can use the object method `.plot()` of your dataframe, then you just need to pass as arguments the name of the columns you want to plot. Each call add a plot to the current plot. Finally to display the figure just execute `plt.show()`\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "history_df.plot('epochs', 'loss', color='g', label='train', ax=ax)\n",
        "history_df.plot('epochs', 'val_loss', color='r', label='test', ax=ax)\n",
        "\n",
        "plt.title('Evolution of the loss')\n",
        "plt.show()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "history_df.plot('epochs', 'accuracy', color='g', label='train', ax=ax)\n",
        "history_df.plot('epochs', 'val_accuracy', color='r', label='test', ax=ax)\n",
        "\n",
        "plt.title('Evolution of the accuracy')\n",
        "plt.show()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mq1ffpkR-eF"
      },
      "source": [
        "#### Prediction\n",
        "\n",
        "Here we'll predict with our Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DxFxPSVRyeP"
      },
      "source": [
        "# TODO: use your model to predict on your test data sample, retrieve the probabilities output and the class output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB3NpH8dMVvC"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "predictions_test_flatten = model.predict(x_test_flatten)\n",
        "y_pred_mlp = np.argmax(predictions_test_flatten, axis=1)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeEUZY4bVR9L"
      },
      "source": [
        "# We define this helper function to plot the probabilities distribution for a given prediction\n",
        "def plot_value_array(i, predictions_array, true_labels):\n",
        "  '''\n",
        "  Plot the probabilities distribution for the prediction of index i in\n",
        "  predictions_array and the true label at position i in the true_labels array.\n",
        "  '''\n",
        "  predictions_array, true_label = predictions_array[i], true_labels[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(10))\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DtzZlS_Vfv8"
      },
      "source": [
        "# TODO: plot the prediction of some example with its image as well\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJKdZUEqMcPD"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "ind = 53\n",
        "plt.imshow(x_train_continuous[ind], cmap='Greys')\n",
        "plt.show()\n",
        "\n",
        "plot_value_array(ind, predictions_test_flatten, y_test)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6ptwMhTV3fq"
      },
      "source": [
        "# TODO: plot misclassified samples in a grid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJol16-iMmaB"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "fig, axs = plt.subplots(nrows=2, ncols=5, figsize=(14, 10),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for ax, i in zip(axs.flat, range(num_outputs)):\n",
        "    # Find a miss-classified image of class i\n",
        "    img_index = np.arange(len(y_test))[(y_test == i) & (y_pred_mlp != i)][0]\n",
        "    ax.imshow(x_test_continuous[img_index].reshape((28, 28)), cmap='Greys')\n",
        "    ax.set_title(f'Class {i} - Prediction {y_pred_mlp[img_index]}')\n",
        "\n",
        "plt.suptitle('Miss-classified samples with MLP')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQrdzK6I3wyS"
      },
      "source": [
        "##Conclusion\n",
        "\n",
        "Well done, you've built your first Neural Network to classify handwritten digits and beat without tuning a Machine-Learning based approach !!\n"
      ]
    }
  ]
}
