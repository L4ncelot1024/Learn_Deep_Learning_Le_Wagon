{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "03-Transfer-Learning_CHALLENGE",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/L4ncelot1024/Learn_Deep_Learning_Le_Wagon/blob/main/Day4/03_Transfer_Learning_CHALLENGE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHK6DyunSbs4"
      },
      "source": [
        "# Cat vs. Dog Image Classification\n",
        "\n",
        "In the previous, we built a convnet from scratch, and were able to achieve an accuracy of about 70%. \n",
        "\n",
        "In this exercise, we'll look at two techniques for repurposing feature data generated from image models that have already been trained on large sets of data, **feature extraction** and **fine tuning**, and use them to improve the accuracy of our cat vs. dog classification model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auRhmaDC6BOG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a40f87dc-cac7-44a8-d8d5-91b672f099fc"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmvdriJS5-l5"
      },
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVlROgOu6ag-"
      },
      "source": [
        "## Data\n",
        "\n",
        "Here we download and process the data like in the previous exercise !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9O0z72L6hV9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9dd04bc4-4a30-445b-d6f0-12364542b4da"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-24 22:19:27--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.202.128, 2607:f8b0:400e:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.202.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   226MB/s    in 0.3s    \n",
            "\n",
            "2019-11-24 22:19:32 (226 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG2j89gb6hYl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5b18c86b-1e90-4616-ed66-2936219dfafa"
      },
      "source": [
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our test cat pictures\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "\n",
        "# Directory with our test dog pictures\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "train_dog_fnames.sort()\n",
        "\n",
        "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
        "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
        "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
        "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training cat images: 1000\n",
            "total training dog images: 1000\n",
            "total test cat images: 500\n",
            "total test dog images: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2LcDhoe6hap",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5ba6f402-8cc8-48f4-9050-ccfbe495f794"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255, for the train generator we set\n",
        "# the validation split.\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# global settings\n",
        "target_size = (150, 150)\n",
        "batch_size = 20\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "print('Train Dataset')\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,  # This is the source directory for training images\n",
        "        target_size=target_size,  # All images will be resized to 150x150\n",
        "        batch_size=batch_size,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary',\n",
        "        subset='training')\n",
        "\n",
        "print('Validation Dataset')\n",
        "# Flow validation images\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='validation')\n",
        "\n",
        "print('Test Dataset')\n",
        "# Flow validation images in batches of 20 using val_datagen generator\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Dataset\n",
            "Found 1600 images belonging to 2 classes.\n",
            "Validation Dataset\n",
            "Found 400 images belonging to 2 classes.\n",
            "Test Dataset\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI5rmt4UBwXs"
      },
      "source": [
        "## Pre-trained Model\n",
        "\n",
        "One thing that is commonly done in computer vision is to take a model trained on a very large dataset, run it on your own, smaller dataset, and extract the intermediate representations (features) that the model generates. These representations are frequently informative for your own computer vision task, even though the task may be quite different from the problem that the original model was trained on. This versatility and repurposability of convnets is one of the most interesting aspects of deep learning.\n",
        "\n",
        "In our case, we will use the [Inception V3 model](https://arxiv.org/abs/1512.00567) developed at Google, and pre-trained on [ImageNet](http://image-net.org/), a large dataset of web images (1.4M images and 1000 classes). This is a powerful model; let's see what the features that it has learned can do for our cat vs. dog problem.\n",
        "\n",
        "First, we need to pick which intermediate layer of Inception V3 we will use for feature extraction. A common practice is to use the output of the very last layer before the `Flatten` operation, the so-called \"bottleneck layer.\" The reasoning here is that the following fully connected layers will be too specialized for the task the network was trained on, and thus the features learned by these layers won't be very useful for a new task. The bottleneck features, however, retain much generality.\n",
        "\n",
        "Let's instantiate an Inception V3 model preloaded with weights trained on ImageNet:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaXLMtYiF0t9"
      },
      "source": [
        "### Preparing the pre-trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMrbllgAFipZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "60f3d36b-6953-4956-d6ee-11fe9eca26a8"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-24 22:19:35--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  99.3MB/s    in 0.8s    \n",
            "\n",
            "2019-11-24 22:19:36 (99.3 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnRiGBfOF8rq"
      },
      "source": [
        "# TODO: Restore the pre-trained model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nkP7KnSZef-"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>Hints\n",
        "</summary>\n",
        "Check here tensorflow.keras.applications.inception_v3 to find the architecture of InceptionV3\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "# By specifying the include_top=False argument, we load a network that\n",
        "# doesn't include the classification layers at the top—ideal for feature extraction.\n",
        "pre_trained_model = InceptionV3(\n",
        "    input_shape=(150, 150, 3), include_top=False, weights=None)\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFxrqTuJee5m"
      },
      "source": [
        "Let's make the model non-trainable, since we will only use it for feature extraction; we won't update the weights of the pretrained model during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a38rB3lyedcB"
      },
      "source": [
        "# TODO: make the layers not trainable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGV3HIBFZnaO"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>Hints\n",
        "</summary>\n",
        "A Layer object has an attribute `trainable`\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGBGDiOAepnO"
      },
      "source": [
        "The layer we will use for feature extraction in Inception v3 is called `mixed7`. It is not the bottleneck of the network, but we are using it to keep a sufficiently large feature map (7x7 in this case). (Using the bottleneck layer would have resulting in a 3x3 feature map, which is a bit small.) Let's get the output from `mixed7`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj4rXshqbQlS"
      },
      "source": [
        "# TODO: get the output of the layer named mixed7 in the pre_trained model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkgGiL1KZql2"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>Hints\n",
        "</summary>\n",
        "There is an object method called `get_layer(layer_name)` for a Keras Model object\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape:', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzV5KC5a7Bm8"
      },
      "source": [
        "### Building the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxHk6XQLeUWh"
      },
      "source": [
        "\n",
        "Now let's build our model architecture with a fully connected classifier on top of the output of our pre-trained model and train it for only a few epochs (2-5) since there is only the classification layers to optimize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMXb913pbvFg"
      },
      "source": [
        "# TODO: Use the Keras Functional API to create the classification layers on top\n",
        "# of last_output and instantiate a Keras model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aj6ZhrKZrxC"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>Hints\n",
        "</summary>\n",
        "You just need to sequentially add the layer with the Keras method like this\n",
        "\n",
        "```python\n",
        "x = myLayer(previous_output)\n",
        "x = myLayer(x)\n",
        "...\n",
        "model = Model(pre_trained_model.input, x)\n",
        "```\n",
        "\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Configure and compile the model\n",
        "model = Model(pre_trained_model.input, x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blhq2MAUeyGA"
      },
      "source": [
        "# TODO: train the model for 3 epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4CEVDgoZtCh"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "num_epochs = 3\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.samples // batch_size,  # 2000 images = batch_size * steps\n",
        "      epochs=num_epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps = validation_generator.samples // batch_size,\n",
        "      verbose=2)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzU9y0O99JCd"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI5GF5EZ9JIY"
      },
      "source": [
        "# TODO: evaluate on the test set and check how your metrics evolve during training to see check for overfitting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXloAFFKZuGo"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "test_loss, accuracy_test_nn = model.evaluate(test_generator, verbose=2)\n",
        "print(f'Test model accuracy: {accuracy_test_nn}')\n",
        "\n",
        "history_df = pd.DataFrame(history.history).reset_index().rename(columns={'index': 'epochs'})\n",
        "history_df.tail()\n",
        "\n",
        "fig, axes = plt.subplots(2, 1, figsize=(14, 12))\n",
        "\n",
        "for i, metric in enumerate(['loss', 'accuracy']):\n",
        "  ax = axes[i]\n",
        "  history_df.plot('epochs', f'{metric}', color='g', label='train', ax=ax)\n",
        "  history_df.plot('epochs', f'val_{metric}', color='r', label='val', ax=ax)\n",
        "  ax.set_ylabel(metric)\n",
        "plt.show()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRjyAkE62aOG"
      },
      "source": [
        "You can see that we reach a validation accuracy of 88–90% very quickly. This is much better than the small model we trained from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt15y6IS2pBo"
      },
      "source": [
        "## Fine-Tuning\n",
        "\n",
        "In our feature-extraction experiment, we only tried adding two classification layers on top of an Inception V3 layer. The weights of the pretrained network were not updated during training. One way to increase performance even further is to \"fine-tune\" the weights of the top layers of the pretrained model alongside the training of the top-level classifier. A couple of important notes on fine-tuning:\n",
        "\n",
        "- **Fine-tuning should only be attempted *after* you have trained the top-level classifier with the pretrained model set to non-trainable**. If you add a randomly initialized classifier on top of a pretrained model and attempt to train all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier), and your pretrained model will just forget everything it has learned.\n",
        "- Additionally, we **fine-tune only the *top layers* of the pre-trained model** rather than all layers of the pretrained model because, in a convnet, the higher up a layer is, the more specialized it is. The first few layers in a convnet learn very simple and generic features, which generalize to almost all types of images. But as you go higher up, the features are increasingly specific to the dataset that the model is trained on. The goal of fine-tuning is to adapt these specialized features to work with the new dataset.\n",
        "- When fine-tuning you're close to the end of the optimization part of your weights, so you need to use an optimizer with a pretty small **learning rate** so you don't modify too much your weigths (remember we call this a **fine** tuning)\n",
        "\n",
        "All we need to do to implement fine-tuning is to set the top layers of Inception V3 to be trainable, recompile the model (necessary for these changes to take effect), and resume training. Let's unfreeze all layers belonging to the `mixed7` module—i.e., all layers found after `mixed6`—and recompile the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX9KyQwk_O9Z"
      },
      "source": [
        "# TODO: Print the layers present in the pre-trained model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0RE4u2GZvoH"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "print([layer.name for layer in pre_trained_model.layers])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l_J4S0Z2rgg"
      },
      "source": [
        "# TODO: Set to trainable all the layers after mixed6 and compile again your model\n",
        "# (but don't initialize it again since you want to keep your weights value)\n",
        "# with a relevant optimizer. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_S-eDOXZwwd"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>Hints\n",
        "</summary>\n",
        "Let's use a Stochastic Gradient Descent (see tensorflow.keras.optimizers.SGD)\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "unfreeze = False\n",
        "\n",
        "# Unfreeze all models after \"mixed6\"\n",
        "for layer in pre_trained_model.layers:\n",
        "  if unfreeze:\n",
        "    layer.trainable = True\n",
        "  if layer.name == 'mixed6':\n",
        "    unfreeze = True\n",
        "\n",
        "# As an optimizer, here we will use SGD \n",
        "# with a very low learning rate (0.00001)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=SGD(\n",
        "                  lr=0.00001, \n",
        "                  momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_GgDGG4Y_hJ"
      },
      "source": [
        "# TODO: train the model for 30 epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRNX9yt7Z2zA"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "num_epochs = 30\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.samples // batch_size,  \n",
        "      epochs=num_epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps = validation_generator.samples // batch_size,\n",
        "      verbose=2)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG6NsTTD__pE"
      },
      "source": [
        "# TODO: evaluate on the test set and check how your metrics evolve during\n",
        "# training to see check for overfitting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1koECbKZ34q"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "\n",
        "test_loss, accuracy_test_nn = model.evaluate(test_generator, verbose=2)\n",
        "print(f'Test model accuracy: {accuracy_test_nn}')\n",
        "\n",
        "\n",
        "history_df = pd.DataFrame(history.history).reset_index().rename(columns={'index': 'epochs'})\n",
        "history_df.tail()\n",
        "\n",
        "fig, axes = plt.subplots(2, 1, figsize=(14, 12))\n",
        "\n",
        "for i, metric in enumerate(['loss', 'accuracy']):\n",
        "  ax = axes[i]\n",
        "  history_df.plot('epochs', f'{metric}', color='g', label='train', ax=ax)\n",
        "  history_df.plot('epochs', f'val_{metric}', color='r', label='val', ax=ax)\n",
        "  ax.set_ylabel(metric)\n",
        "plt.show()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK95OfId__yG"
      },
      "source": [
        "Note your observations"
      ]
    }
  ]
}