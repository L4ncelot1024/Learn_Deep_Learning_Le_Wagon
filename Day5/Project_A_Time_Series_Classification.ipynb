{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_A_Time_Series_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/L4ncelot1024/Learn_Deep_Learning_Le_Wagon/blob/main/Day5/Project_A_Time_Series_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG11j8CIrHl9"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this project you will build a model for human activity recognition.\n",
        "\n",
        "Human activity recognition is the problem of classifying sequences of accelerometer data recorded by specialized harnesses or smart phones into known well-defined movements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08FypM3iuDvn"
      },
      "source": [
        "  %tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DATnLEQes1j8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiKozfjhrtkY"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CidjEI65q2lg",
        "outputId": "587e99d3-4c35-4a49-99e4-d9170a2ce299"
      },
      "source": [
        "# Download the data\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n",
        "\n",
        "# Unzip the data \n",
        "!unzip UCI\\ HAR\\ Dataset.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-20 21:33:45--  https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60999314 (58M) [application/x-httpd-php]\n",
            "Saving to: ‘UCI HAR Dataset.zip.2’\n",
            "\n",
            "UCI HAR Dataset.zip 100%[===================>]  58.17M  73.7MB/s    in 0.8s    \n",
            "\n",
            "2021-05-20 21:33:46 (73.7 MB/s) - ‘UCI HAR Dataset.zip.2’ saved [60999314/60999314]\n",
            "\n",
            "Archive:  UCI HAR Dataset.zip\n",
            "replace UCI HAR Dataset/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/UCI HAR Dataset/._.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace UCI HAR Dataset/activity_labels.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace __MACOSX/UCI HAR Dataset/._activity_labels.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace UCI HAR Dataset/features.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypDOohTNsfve"
      },
      "source": [
        "# list the content of the unzip dataset folder\n",
        "!mv UCI\\ HAR\\ Dataset HARDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQEmig8Osl5O"
      },
      "source": [
        "# Helper functions to load the data\n",
        "\n",
        "\n",
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "\tdataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values\n",
        "\n",
        "\n",
        "# load a list of files into a 3D array of [samples, timesteps, features]\n",
        "def load_group(filenames, prefix=''):\n",
        "\tloaded = list()\n",
        "\tfor name in filenames:\n",
        "\t\tdata = load_file(prefix + name)\n",
        "\t\tloaded.append(data)\n",
        "\t# stack group so that features are the 3rd dimension\n",
        "\tloaded = np.dstack(loaded)\n",
        "\treturn loaded\n",
        "\n",
        "# load a dataset group, such as train or test\n",
        "def load_dataset_group(group, prefix=''):\n",
        "\tfilepath = prefix + group + '/Inertial Signals/'\n",
        "\t# load all 9 files as a single array\n",
        "\tfilenames = list()\n",
        "\t# total acceleration\n",
        "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
        "\t# body acceleration\n",
        "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
        "\t# body gyroscope\n",
        "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "\t# load input data\n",
        "\tX = load_group(filenames, filepath)\n",
        "\t# load class output\n",
        "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "\treturn X, y\n",
        "\n",
        "# load the dataset, returns train and test X and y elements\n",
        "def load_dataset(prefix=''):\n",
        "\t# load all train\n",
        "\ttrainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n",
        "\tprint(trainX.shape, trainy.shape)\n",
        "\t# load all test\n",
        "\ttestX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n",
        "\tprint(testX.shape, testy.shape)\n",
        "\t# zero-offset class values\n",
        "\ttrainy = trainy - 1\n",
        "\ttesty = testy - 1\n",
        "\t# one hot encode y\n",
        "\ttrainy = to_categorical(trainy)\n",
        "\ttesty = to_categorical(testy)\n",
        "\tprint(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
        "\treturn trainX, trainy, testX, testy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ88aWR1tllG",
        "outputId": "ba583304-ba49-4f3f-87d8-a8de2183e6fa"
      },
      "source": [
        "trainX, trainy, testX, testy = load_dataset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7352, 128, 9) (7352, 1)\n",
            "(2947, 128, 9) (2947, 1)\n",
            "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fYzXTz1uwia"
      },
      "source": [
        "There are three main signal types in the raw data: total acceleration, body acceleration, and body gyroscope. Each has 3 axises of data. This means that there are a total of nine variables for each time step.\n",
        "\n",
        "Further, each series of data has been partitioned into overlapping windows of 2.56 seconds of data, or 128 time steps. These windows of data correspond to the windows of engineered features (rows) in the previous section.\n",
        "\n",
        "This means that one row of data has (128 * 9), or 1,152 elements.\n",
        "\n",
        "We provide you with the helper functions to read the data and to build all the elements needed for your project:\n",
        "- the list of time series of your train and test input, as a `np.ndarray`;\n",
        "- the list of their corresponding labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M9vbrSVvJu9"
      },
      "source": [
        "# Time to play around with the data !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xL_mJxov4Qt"
      },
      "source": [
        "Here is a suggested step-by-step workflow to follow to address a modeling project:\n",
        "\n",
        "* **Display your dataset (visually!)**: plot/print your \"observations\" - what are observations here ? what are labels ? How to display them ?\n",
        "* **Task**: Think about your task and how you want to solve it !\n",
        "* **Modeling**: first, start with a simple baseline to have an end-to-end working model, you'll think later on how to improve it\n",
        "* **Fit**: Your model might have some hyper-parameters you want to optimize so keep a validation set out of your training data !\n",
        "* **Assess model performance**: which metrics should I use ?\n",
        "* **Test your model**: you have a test data set for that !\n",
        "* **Improve your model**: why my model is not yet good enough? Is it because of under-fitting or because of over-fitting? See below for a list of things you could try, \n",
        "* **Challenge your results**: What else could you do ? Which information are you discarding which could be important?\n",
        "* **Present your results**:\n",
        "* **Think beyond this project !**: Find out another application, using the same kind of model, which could be interesting, and share it with others !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRpnGpFJvMGr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}